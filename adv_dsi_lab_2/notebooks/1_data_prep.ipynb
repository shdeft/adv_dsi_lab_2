{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load & Explore Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/shadieftekhari/Desktop/UTS/adv_dsi_lab_2/adv_dsi_lab_2/adv_dsi_lab_2/data/raw/day-1.csv')\n",
    "df.head()\n",
    "df.shape\n",
    "df.info()\n",
    "df.describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Prep\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#duplicate Data\n",
    "df_cleaned = df.copy()\n",
    "\n",
    "#Drop column instant\n",
    "df_cleaned.drop('instant',axis=1,inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Function to convert into datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_date(df, cols:list):\n",
    "    \"\"\"Convert specified columns from a Pandas dataframe into datetime\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        Input dataframe\n",
    "    cols : list\n",
    "        List of columns to be converted\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        Pandas dataframe with converted columns\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "\n",
    "    for col in cols:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_datetime(df[col])\n",
    "    return df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call Function to convert to date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned = convert_to_date(df_cleaned, ['dteday'])\n",
    "# Extract the year\n",
    "df_cleaned['yr'] = df_cleaned['dteday'].dt.year\n",
    "# Extract the month\n",
    "df_cleaned['mnth'] = df_cleaned['dteday'].dt.month_name()\n",
    "# Extract the Day\n",
    "df_cleaned['weekday'] = df_cleaned['dteday'].dt.day_name()\n",
    "\n",
    "## Season Dictionary Mapping\n",
    "season_mapping = {\n",
    "    1: 'winter',\n",
    "    2: 'spring',\n",
    "    3: 'summer',\n",
    "    4: 'autumn',\n",
    "}\n",
    "df_cleaned['season'] = df_cleaned['season'].map(season_mapping)\n",
    "\n",
    "## Weather Dictionary Mapping \n",
    "eather_mapping = {\n",
    "    1: 'clear',\n",
    "    2: 'cloudy',\n",
    "    3: 'rain',\n",
    "    4: 'heavy'\n",
    "}\n",
    "df_cleaned['weathersit'] = df_cleaned['weathersit'].map(weather_mapping)\n",
    "\n",
    "# Change the Holiday Value\n",
    "df_cleaned.loc[df_cleaned['dteday'] == '2011-01-01', 'holiday'] = 1\n",
    "df_cleaned['holidaydate'] = np.nan\n",
    "df_cleaned = convert_to_date(df_cleaned, ['holidaydate'])\n",
    "holiday_mask = df_cleaned['holiday'] == 1\n",
    "\n",
    "# Change the values of holidaydate to be equals to dteday for all the observations that have the value 1 in column holiday (use holiday_mask)\n",
    "df_cleaned.loc[holiday_mask, 'holidaydate'] = df_cleaned.loc[holiday_mask, 'dteday']\n",
    "\n",
    "# New column called last_holiday that will be equals to holidaydate but with forward filling for missing values \n",
    "df_cleaned['last_holiday'] = df_cleaned['holidaydate'].fillna(method='ffill')\n",
    "\n",
    "# Create a new column called last_holiday that will be equals to holidaydate but with back filling for missing values\n",
    "df_cleaned['next_holiday'] = df_cleaned['holidaydate'].fillna(method='bfill')\n",
    "\n",
    "# Replace missing values for next_holiday with the timestamp '2013-01-01\n",
    "df_cleaned['next_holiday'].fillna(pd.Timestamp('2013-01-01'), inplace=True)\n",
    "\n",
    "# Calculate the number of days for each observation between the current date and last holiday date. Save the results in a new column called days_last_holiday\n",
    "df_cleaned['days_next_holiday'] = (df_cleaned['next_holiday'] - df_cleaned['dteday']).dt.days\n",
    "\n",
    "# Create a variable called cat_cols that contains the names of the categorical columns\n",
    "cat_cols = ['season','mnth','holiday','weekday','workingday','weathersit']\n",
    "\n",
    "# Perform One-Hot encoding on the categorical features\n",
    "df_cleaned = pd.get_dummies(df_cleaned, columns=cat_cols)\n",
    "\n",
    "# Save the dataframe in the /data/interim folder\n",
    "df_cleaned.to_csv('/Users/shadieftekhari/Desktop/UTS/adv_dsi_lab_2/adv_dsi_lab_2/adv_dsi_lab_2/data/interim/day.csv', index=False)\n",
    "\n",
    "# Remove the following columns: 'dteday', 'holidaydate', 'last_holiday', 'next_holiday'\n",
    "df_cleaned.drop(['dteday', 'holidaydate', 'last_holiday', 'next_holiday'], axis=1, inplace=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a subset function\n",
    "def subset_x_y(target, features, start_index:int, end_index:int):\n",
    "    \"\"\"Keep only the rows for X and y sets from the specified indexes\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    target : pd.DataFrame\n",
    "        Dataframe containing the target\n",
    "    features : pd.DataFrame\n",
    "        Dataframe containing all features\n",
    "    features : int\n",
    "        Index of the starting observation\n",
    "    features : int\n",
    "        Index of the ending observation\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        Subsetted Pandas dataframe containing the target\n",
    "    pd.DataFrame\n",
    "        Subsetted Pandas dataframe containing all features\n",
    "    \"\"\"\n",
    "\n",
    "    return features[start_index:end_index], target[start_index:end_index]\n",
    "\n",
    "# Create a function to split data by time\n",
    "def split_sets_by_time(df, target_col, test_ratio=0.2):\n",
    "    \"\"\"Split sets by indexes for an ordered dataframe\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        Input dataframe\n",
    "    target_col : str\n",
    "        Name of the target column\n",
    "    test_ratio : float\n",
    "        Ratio used for the validation and testing sets (default: 0.2)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Numpy Array\n",
    "        Features for the training set\n",
    "    Numpy Array\n",
    "        Target for the training set\n",
    "    Numpy Array\n",
    "        Features for the validation set\n",
    "    Numpy Array\n",
    "        Target for the validation set\n",
    "    Numpy Array\n",
    "        Features for the testing set\n",
    "    Numpy Array\n",
    "        Target for the testing set\n",
    "    \"\"\"\n",
    "\n",
    "    df_copy = df.copy()\n",
    "    target = df_copy.pop(target_col)\n",
    "    cutoff = int(len(target) / 5)\n",
    "\n",
    "    X_train, y_train = subset_x_y(target=target, features=df_copy, start_index=0, end_index=-cutoff*2)\n",
    "    X_val, y_val     = subset_x_y(target=target, features=df_copy, start_index=-cutoff*2, end_index=-cutoff)\n",
    "    X_test, y_test   = subset_x_y(target=target, features=df_copy, start_index=-cutoff, end_index=len(target))\n",
    "\n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test\n",
    "\n",
    "# Import your new function split_sets_by_time and split the data into several sets\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = split_sets_by_time(df_cleaned, 'cnt', test_ratio=0.2)\n",
    "\n",
    "# Create a function to save sets\n",
    "def save_sets(X_train=None, y_train=None, X_val=None, y_val=None, X_test=None, y_test=None, path='/Users/shadieftekhari/Desktop/UTS/adv_dsi_lab_2/adv_dsi_lab_2/adv_dsi_lab_2/data/processed/'):\n",
    "    \"\"\"Save the different sets locally\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X_train: Numpy Array\n",
    "        Features for the training set\n",
    "    y_train: Numpy Array\n",
    "        Target for the training set\n",
    "    X_val: Numpy Array\n",
    "        Features for the validation set\n",
    "    y_val: Numpy Array\n",
    "        Target for the validation set\n",
    "    X_test: Numpy Array\n",
    "        Features for the testing set\n",
    "    y_test: Numpy Array\n",
    "        Target for the testing set\n",
    "    path : str\n",
    "        Path to the folder where the sets will be saved (default: '/Users/shadieftekhari/Desktop/UTS/adv_dsi_lab_2/adv_dsi_lab_2/adv_dsi_lab_2/data/processed/')\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "\n",
    "    if X_train is not None:\n",
    "      np.save(f'{path}X_train', X_train)\n",
    "    if X_val is not None:\n",
    "      np.save(f'{path}X_val',   X_val)\n",
    "    if X_test is not None:\n",
    "      np.save(f'{path}X_test',  X_test)\n",
    "    if y_train is not None:\n",
    "      np.save(f'{path}y_train', y_train)\n",
    "    if y_val is not None:\n",
    "      np.save(f'{path}y_val',   y_val)\n",
    "    if y_test is not None:\n",
    "      np.save(f'{path}y_test',  y_test)\n",
    "\n",
    "# Create a function to load sets\n",
    "def load_sets(path='../data/processed/', val=False):\n",
    "    \"\"\"Load the different locally save sets\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    path : str\n",
    "        Path to the folder where the sets are saved (default: '/Users/shadieftekhari/Desktop/UTS/adv_dsi_lab_2/adv_dsi_lab_2/adv_dsi_lab_2/data/processed/')\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Numpy Array\n",
    "        Features for the training set\n",
    "    Numpy Array\n",
    "        Target for the training set\n",
    "    Numpy Array\n",
    "        Features for the validation set\n",
    "    Numpy Array\n",
    "        Target for the validation set\n",
    "    Numpy Array\n",
    "        Features for the testing set\n",
    "    Numpy Array\n",
    "        Target for the testing set\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    import os.path\n",
    "\n",
    "    X_train = np.load(f'{path}X_train.npy') if os.path.isfile(f'{path}X_train.npy') else None\n",
    "    X_val   = np.load(f'{path}X_val.npy'  ) if os.path.isfile(f'{path}X_val.npy')   else None\n",
    "    X_test  = np.load(f'{path}X_test.npy' ) if os.path.isfile(f'{path}X_test.npy')  else None\n",
    "    y_train = np.load(f'{path}y_train.npy') if os.path.isfile(f'{path}y_train.npy') else None\n",
    "    y_val   = np.load(f'{path}y_val.npy'  ) if os.path.isfile(f'{path}y_val.npy')   else None\n",
    "    y_test  = np.load(f'{path}y_test.npy' ) if os.path.isfile(f'{path}y_test.npy')  else None\n",
    "\n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test\n",
    "\n",
    "# Import your new function and save the sets into the folder data/processed\n",
    "save_sets(X_train, y_train, X_val, y_val, X_test, y_test, path='/Users/shadieftekhari/Desktop/UTS/adv_dsi_lab_2/adv_dsi_lab_2/adv_dsi_lab_2/data/processed/')\n",
    "\n",
    "# Calculate the average of the target variable for the training set and save it into a variable called y_mean\n",
    "y_mean = y_train.mean()\n",
    "\n",
    "# Create a numpy array called y_base of dimensions (len(y_train), 1) filled with this value\n",
    "y_base = np.full((len(y_train), 1), y_mean)\n",
    "\n",
    "# In src/models/ create a file called performance.py. Inside it you will define a function called print_reg_perf\n",
    "def print_reg_perf(y_preds, y_actuals, set_name=None):\n",
    "    \"\"\"Print the RMSE and MAE for the provided data\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y_preds : Numpy Array\n",
    "        Predicted target\n",
    "    y_actuals : Numpy Array\n",
    "        Actual target\n",
    "    set_name : str\n",
    "        Name of the set to be printed\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    \"\"\"\n",
    "    from sklearn.metrics import mean_squared_error as mse\n",
    "    from sklearn.metrics import mean_absolute_error as mae\n",
    "\n",
    "    print(f\"RMSE {set_name}: {mse(y_actuals, y_preds, squared=False)}\")\n",
    "    print(f\"MAE {set_name}: {mae(y_actuals, y_preds)}\")\n",
    "\n",
    "# Display the RMSE and MAE scores of this baseline model\n",
    "    print_reg_perf(y_preds=y_base, y_actuals=y_train, set_name='Training')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
